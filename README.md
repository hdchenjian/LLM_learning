### 深度学习笔记

#### 手戳一个LLaMA2 大模型，支持旋转位置编码、稠密模型及混合专家模型（Mixture of Experts, MoE）
- [LLaMA2](./train/llama2.c/)

#### 基于transformer 的文本翻译，支持英-中、英-法 语言翻译实现
- [Seq2Seq](./d2l/chapter_9_7_seq2seq.py)
- [Transformer](./d2l/chapter10_7_transformer.py)
- [Bert](./d2l/chapter14_7_bert.py)

**train dataset**
- [英-法](https://www.manythings.org/anki/fra-eng.zip)
- [英-中](https://www.manythings.org/anki/cmn-eng.zip)

